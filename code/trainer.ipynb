{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "\n",
    "from models import SMD_Unet\n",
    "\n",
    "import numpy as np\n",
    "from data_generator import DR_Generator\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, epochs, optimizer, for_recons, alpha, beta=None):\n",
    "        '''\n",
    "        for_recons : bool, 학습 단계 구분하기 위함\n",
    "        alpha : recons loss에 곱해줄 가중치\n",
    "        beta : [] , mask loss에 곱해줄 가중치 리스트\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.for_recons = for_recons\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta \n",
    "        if beta!=None:\n",
    "            self.b1, self.b2, self.b3, self.b4 = beta\n",
    "        \n",
    "        # reconstruction만 학습하는거면 안쓰는 decoder trainable=False로 해주기\n",
    "        if self.for_recons:\n",
    "            self.model.HardExudate.trainable=False\n",
    "            self.model.Hemohedge.trainable=False\n",
    "            self.model.Microane.trainable=False\n",
    "            self.model.SoftExudates.trainable=False\n",
    "        else:\n",
    "            self.model.HardExudate.trainable=True\n",
    "            self.model.Hemohedge.trainable=True\n",
    "            self.model.Microane.trainable=True\n",
    "            self.model.SoftExudates.trainable=True\n",
    "\n",
    "    # loss 함수 계산하는 부분 \n",
    "    # return 값이 텐서여야 하는건가? -> 아마도 그런 것 같다.\n",
    "    def dice_loss(self, inputs, targets, smooth = 1.):\n",
    "        inputs = inputs\n",
    "        targets = targets.numpy()\n",
    "\n",
    "        dice_losses = []\n",
    "        for input, target in zip(inputs, targets): \n",
    "            input_flat = input.flatten()\n",
    "            target_flat = target.flatten()\n",
    "            \n",
    "            intersection = np.sum(input_flat * target_flat)\n",
    "            dice_coef = (2. * intersection + smooth) / (np.sum(input_flat) + np.sum(target_flat) + smooth)\n",
    "\n",
    "            dice_losses.append(1. - dice_coef)\n",
    "            \n",
    "        result = tf.reduce_mean(dice_losses) \n",
    "        return tf.convert_to_tensor(result) # tensor로 바꿔주기\n",
    "    \n",
    "    def mean_square_error(self, input_hats, inputs):\n",
    "        inputs = inputs\n",
    "        input_hats = input_hats.numpy()\n",
    "        \n",
    "        mses = []\n",
    "        for input_hat, input in zip(input_hats, inputs):\n",
    "            mses.append(tf.reduce_mean(tf.square(input_hat - input)).numpy())\n",
    "            \n",
    "        result = np.mean(mses) # 배치 나눠서 계산하고 평균해주기\n",
    "        return tf.convert_to_tensor(result) # tensor로 바꿔주기\n",
    "\n",
    "    @tf.function\n",
    "    def train_on_batch(self, x_batch_train, y_batch_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self.model(x_batch_train, only_recons=self.for_recons)    # 모델이 예측한 결과\n",
    "#             input_hat, ex_hat, he_hat, ma_hat, se_hat = preds\n",
    "            \n",
    "#             ex, he, ma, se = y_batch_train\n",
    "            \n",
    "            # loss 계산하기\n",
    "            # reconstruction\n",
    "            loss_recons = self.mean_square_error(preds[0], x_batch_train)\n",
    "            \n",
    "            if not self.for_recons:\n",
    "            # ex, he, ma, se\n",
    "                ex_loss = self.dice_loss(y_batch_train[0], preds[1])\n",
    "                he_loss = self.dice_loss(y_batch_train[1], preds[2])\n",
    "                ma_loss = self.dice_loss(y_batch_train[2], preds[3])\n",
    "                se_loss = self.dice_loss(y_batch_train[3], preds[4])            \n",
    "                # loss 가중합 해주기\n",
    "                train_loss = self.b1 * ex_loss + self.b2 * he_loss + self.b3 * ma_loss + self.b4 * se_loss + self.alpha * loss_recons\n",
    "            else:     \n",
    "                train_loss = loss_recons \n",
    "            \n",
    "        grads = tape.gradient(train_loss, self.model.trainable_weights)  # gradient 계산\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))  # Otimizer에게 처리된 그라데이션 적용을 요청\n",
    "        \n",
    "        del preds\n",
    "        \n",
    "        return train_loss\n",
    "\n",
    "    def train(self, train_dataset, val_dataset):\n",
    "        metrics_names = ['train_loss', 'val_loss']\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nEpoch {}/{}\".format(epoch+1, self.epochs))\n",
    "\n",
    "            # train_dataset = train_dataset.take(steps_per_epoch)\n",
    "            # val_dataset = val_dataset.take(val_step)\n",
    "\n",
    "            progBar = Progbar(len(train_dataset), stateful_metrics=metrics_names)\n",
    "\n",
    "            # 데이터 집합의 배치에 대해 반복합니다\n",
    "            for step_train, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                train_loss = self.train_on_batch(x_batch_train, y_batch_train)\n",
    "\n",
    "                # train metric(mean, auc, accuracy 등) 업데이트\n",
    "                # acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "                # train_acc = self.compute_acc(logits, y_batch_train)\n",
    "                values = [('train_loss', train_loss)]\n",
    "                # print('{}'.format((step_train + 1) * self.batch))\n",
    "                progBar.update((step_train + 1) * self.batch, values=values)\n",
    "                \n",
    "                del train_loss\n",
    "                del x_batch_train\n",
    "                del y_batch_train\n",
    "\n",
    "            for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
    "                preds = self.model(x_batch_val, only_recons=self.for_recons)    # 모델이 예측한 결과\n",
    "#                 input_hat, ex_hat, he_hat, ma_hat, se_hat = preds\n",
    "                \n",
    "#                 ex, he, ma, se = y_batch_val\n",
    "                \n",
    "                # loss 계산하기\n",
    "                # reconstruction\n",
    "                loss_recons = self.mean_square_error(preds[0], x_batch_val)\n",
    "                \n",
    "                if not self.for_recons:\n",
    "                # ex, he, ma, se\n",
    "                    ex_loss = self.dice_loss(y_batch_val[0], preds[1])\n",
    "                    he_loss = self.dice_loss(y_batch_val[1], preds[2])\n",
    "                    ma_loss = self.dice_loss(y_batch_val[2], preds[3])\n",
    "                    se_loss = self.dice_loss(y_batch_val[3], preds[4])            \n",
    "                    # loss 가중합 해주기\n",
    "                    val_loss = self.b1 * ex_loss + self.b2 * he_loss + self.b3 * ma_loss + self.b4 * se_loss + self.alpha * loss_recons\n",
    "                else:     \n",
    "                    val_loss = loss_recons\n",
    "                    \n",
    "                del val_loss\n",
    "                del x_batch_val\n",
    "                del y_batch_val\n",
    "                del preds\n",
    "                \n",
    "            values = [('train_loss', train_loss), ('val_loss', val_loss)]\n",
    "            progBar.update((step_train + 1) * self.batch, values=values, finalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"smd__unet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_block (EncoderBlock) multiple                  4719584   \n",
      "_________________________________________________________________\n",
      "decoder_block (DecoderBlock) multiple                  3052269   \n",
      "_________________________________________________________________\n",
      "decoder_block_1 (DecoderBloc multiple                  3052269   \n",
      "_________________________________________________________________\n",
      "decoder_block_2 (DecoderBloc multiple                  3052269   \n",
      "_________________________________________________________________\n",
      "decoder_block_3 (DecoderBloc multiple                  3052269   \n",
      "_________________________________________________________________\n",
      "decoder_block_4 (DecoderBloc multiple                  3052269   \n",
      "=================================================================\n",
      "Total params: 19,980,929\n",
      "Trainable params: 19,967,341\n",
      "Non-trainable params: 13,588\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SMD_Unet(filters=[32, 64, 128, 256, 512])\n",
    "model.build(input_shape=(None, 512, 512, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "masks = ['HardExudate_Masks', 'Hemohedge_Masks', 'Microaneurysms_Masks', 'SoftExudate_Masks']\n",
    "mask_dir = '../data/Seg-set'\n",
    "mask_paths = [os.path.join(mask_dir, mask) for mask in masks]\n",
    "\n",
    "generator_args = {\n",
    "  'dir_path':'../data/Seg-set/Original_Images/',\n",
    "  'mask_path':mask_paths,\n",
    "  'use_mask':True,\n",
    "  'img_size':(512, 512),  \n",
    "  'batch_size':4, # 8로 하면 바로 OOM 뜸\n",
    "  'dataset':'FGADR', # FGADR or EyePacks\n",
    "  'is_train':True\n",
    "}\n",
    "\n",
    "tr_eyepacks_gen = DR_Generator(start_end_index=(0, 500), **generator_args)\n",
    "val_eyepacks_gen = DR_Generator(start_end_index=(500, 600), **generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['smd__unet_1/encoder_block_1/conv_block_55/conv2d_60/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_55/conv2d_60/bias:0', 'smd__unet_1/encoder_block_1/conv_block_55/batch_normalization_55/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_55/batch_normalization_55/beta:0', 'smd__unet_1/encoder_block_1/conv_block_56/conv2d_61/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_56/conv2d_61/bias:0', 'smd__unet_1/encoder_block_1/conv_block_56/batch_normalization_56/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_56/batch_normalization_56/beta:0', 'smd__unet_1/encoder_block_1/conv_block_57/conv2d_62/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_57/conv2d_62/bias:0', 'smd__unet_1/encoder_block_1/conv_block_57/batch_normalization_57/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_57/batch_normalization_57/beta:0', 'smd__unet_1/encoder_block_1/conv_block_58/conv2d_63/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_58/conv2d_63/bias:0', 'smd__unet_1/encoder_block_1/conv_block_58/batch_normalization_58/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_58/batch_normalization_58/beta:0', 'smd__unet_1/encoder_block_1/conv_block_59/conv2d_64/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_59/conv2d_64/bias:0', 'smd__unet_1/encoder_block_1/conv_block_59/batch_normalization_59/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_59/batch_normalization_59/beta:0', 'smd__unet_1/encoder_block_1/conv_block_60/conv2d_65/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_60/conv2d_65/bias:0', 'smd__unet_1/encoder_block_1/conv_block_60/batch_normalization_60/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_60/batch_normalization_60/beta:0', 'smd__unet_1/encoder_block_1/conv_block_61/conv2d_66/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_61/conv2d_66/bias:0', 'smd__unet_1/encoder_block_1/conv_block_61/batch_normalization_61/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_61/batch_normalization_61/beta:0', 'smd__unet_1/encoder_block_1/conv_block_62/conv2d_67/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_62/conv2d_67/bias:0', 'smd__unet_1/encoder_block_1/conv_block_62/batch_normalization_62/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_62/batch_normalization_62/beta:0', 'smd__unet_1/encoder_block_1/conv_block_63/conv2d_68/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_63/conv2d_68/bias:0', 'smd__unet_1/encoder_block_1/conv_block_63/batch_normalization_63/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_63/batch_normalization_63/beta:0', 'smd__unet_1/encoder_block_1/conv_block_64/conv2d_69/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_64/conv2d_69/bias:0', 'smd__unet_1/encoder_block_1/conv_block_64/batch_normalization_64/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_64/batch_normalization_64/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv2d_transpose_20/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv2d_transpose_20/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/conv2d_70/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/conv2d_70/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/batch_normalization_65/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/batch_normalization_65/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/conv2d_71/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/conv2d_71/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/batch_normalization_66/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/batch_normalization_66/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv2d_transpose_21/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv2d_transpose_21/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/conv2d_72/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/conv2d_72/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/batch_normalization_67/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/batch_normalization_67/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/conv2d_73/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/conv2d_73/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/batch_normalization_68/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/batch_normalization_68/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv2d_transpose_22/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv2d_transpose_22/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/conv2d_74/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/conv2d_74/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/batch_normalization_69/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/batch_normalization_69/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/conv2d_75/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/conv2d_75/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/batch_normalization_70/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/batch_normalization_70/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv2d_transpose_23/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv2d_transpose_23/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/conv2d_76/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/conv2d_76/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/batch_normalization_71/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/batch_normalization_71/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/conv2d_77/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/conv2d_77/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/batch_normalization_72/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/batch_normalization_72/beta:0', 'conv_block_73/conv2d_78/kernel:0', 'conv_block_73/conv2d_78/bias:0', 'conv_block_73/batch_normalization_73/gamma:0', 'conv_block_73/batch_normalization_73/beta:0', 'conv2d_79/kernel:0', 'conv2d_79/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_246/3637291740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrainer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m trainer.train(train_dataset=tr_eyepacks_gen,\n\u001b[0m\u001b[1;32m     18\u001b[0m               \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_eyepacks_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               )\n",
      "\u001b[0;32m/tmp/ipykernel_246/1159349791.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# 데이터 집합의 배치에 대해 반복합니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# train metric(mean, auc, accuracy 등) 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_functions_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;31m# Only count the statistics the fitst time, before initialization took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3983\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3984\u001b[0m         \u001b[0mwrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unbound_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3985\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3987\u001b[0m     \u001b[0;31m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_246/1159349791.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x_batch_train, y_batch_train)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# gradient 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Otimizer에게 처리된 그라데이션 적용을 요청\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    620\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \"\"\"\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0m\u001b[1;32m     73\u001b[0m                      ([v.name for _, v in grads_and_vars],))\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['smd__unet_1/encoder_block_1/conv_block_55/conv2d_60/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_55/conv2d_60/bias:0', 'smd__unet_1/encoder_block_1/conv_block_55/batch_normalization_55/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_55/batch_normalization_55/beta:0', 'smd__unet_1/encoder_block_1/conv_block_56/conv2d_61/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_56/conv2d_61/bias:0', 'smd__unet_1/encoder_block_1/conv_block_56/batch_normalization_56/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_56/batch_normalization_56/beta:0', 'smd__unet_1/encoder_block_1/conv_block_57/conv2d_62/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_57/conv2d_62/bias:0', 'smd__unet_1/encoder_block_1/conv_block_57/batch_normalization_57/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_57/batch_normalization_57/beta:0', 'smd__unet_1/encoder_block_1/conv_block_58/conv2d_63/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_58/conv2d_63/bias:0', 'smd__unet_1/encoder_block_1/conv_block_58/batch_normalization_58/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_58/batch_normalization_58/beta:0', 'smd__unet_1/encoder_block_1/conv_block_59/conv2d_64/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_59/conv2d_64/bias:0', 'smd__unet_1/encoder_block_1/conv_block_59/batch_normalization_59/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_59/batch_normalization_59/beta:0', 'smd__unet_1/encoder_block_1/conv_block_60/conv2d_65/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_60/conv2d_65/bias:0', 'smd__unet_1/encoder_block_1/conv_block_60/batch_normalization_60/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_60/batch_normalization_60/beta:0', 'smd__unet_1/encoder_block_1/conv_block_61/conv2d_66/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_61/conv2d_66/bias:0', 'smd__unet_1/encoder_block_1/conv_block_61/batch_normalization_61/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_61/batch_normalization_61/beta:0', 'smd__unet_1/encoder_block_1/conv_block_62/conv2d_67/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_62/conv2d_67/bias:0', 'smd__unet_1/encoder_block_1/conv_block_62/batch_normalization_62/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_62/batch_normalization_62/beta:0', 'smd__unet_1/encoder_block_1/conv_block_63/conv2d_68/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_63/conv2d_68/bias:0', 'smd__unet_1/encoder_block_1/conv_block_63/batch_normalization_63/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_63/batch_normalization_63/beta:0', 'smd__unet_1/encoder_block_1/conv_block_64/conv2d_69/kernel:0', 'smd__unet_1/encoder_block_1/conv_block_64/conv2d_69/bias:0', 'smd__unet_1/encoder_block_1/conv_block_64/batch_normalization_64/gamma:0', 'smd__unet_1/encoder_block_1/conv_block_64/batch_normalization_64/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv2d_transpose_20/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv2d_transpose_20/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/conv2d_70/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/conv2d_70/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/batch_normalization_65/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_65/batch_normalization_65/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/conv2d_71/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/conv2d_71/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/batch_normalization_66/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_20/conv_block_66/batch_normalization_66/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv2d_transpose_21/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv2d_transpose_21/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/conv2d_72/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/conv2d_72/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/batch_normalization_67/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_67/batch_normalization_67/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/conv2d_73/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/conv2d_73/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/batch_normalization_68/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_21/conv_block_68/batch_normalization_68/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv2d_transpose_22/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv2d_transpose_22/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/conv2d_74/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/conv2d_74/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/batch_normalization_69/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_69/batch_normalization_69/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/conv2d_75/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/conv2d_75/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/batch_normalization_70/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_22/conv_block_70/batch_normalization_70/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv2d_transpose_23/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv2d_transpose_23/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/conv2d_76/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/conv2d_76/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/batch_normalization_71/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_71/batch_normalization_71/beta:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/conv2d_77/kernel:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/conv2d_77/bias:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/batch_normalization_72/gamma:0', 'smd__unet_1/decoder_block_5/upsample_block_23/conv_block_72/batch_normalization_72/beta:0', 'conv_block_73/conv2d_78/kernel:0', 'conv_block_73/conv2d_78/bias:0', 'conv_block_73/batch_normalization_73/gamma:0', 'conv_block_73/batch_normalization_73/beta:0', 'conv2d_79/kernel:0', 'conv2d_79/bias:0']."
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
    "\n",
    "model = SMD_Unet(filters=[32, 64, 128, 256, 512])\n",
    "\n",
    "trainer_args = {\n",
    "    'model':model,\n",
    "    'epochs':1,\n",
    "    'optimizer':optimizer,\n",
    "    'for_recons':True,\n",
    "    'alpha':1.0,\n",
    "    'beta':[1.0, 1.0, 1.0, 1.0]\n",
    "}\n",
    "trainer = Trainer(**trainer_args)\n",
    "\n",
    "trainer.train(train_dataset=tr_eyepacks_gen,\n",
    "              val_dataset=val_eyepacks_gen\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def ConvBlock(x, n_filters):\n",
    "    x = keras.layers.Conv2D(n_filters, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def UpsampleBlock(x, skip, n_filters):\n",
    "    x = keras.layers.Conv2DTranspose(n_filters, (2, 2), strides=2, padding='same')(x)\n",
    "    x = keras.layers.Concatenate()([x, skip]) \n",
    "    x = ConvBlock(x, n_filters)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Encoder(x, filters):\n",
    "    skips = []\n",
    "\n",
    "    for f in filters:\n",
    "        x = ConvBlock(x, f)\n",
    "        x = ConvBlock(x, f)\n",
    "        # 맨 마지막 층을 제외하고는 skip connection, downsampling을 진행\n",
    "        if f != filters[-1]:\n",
    "            skips.append(x)\n",
    "            x = keras.layers.MaxPooling2D(2)(x)\n",
    "      \n",
    "    return x, skips\n",
    "\n",
    "def Decoder(x, filters, skips):\n",
    "    for f, skip in zip(filters, skips):\n",
    "        x = keras.layers.Conv2DTranspose(f, (2, 2), strides=2, padding='same')(x)\n",
    "        x = ConvBlock(x, f)\n",
    "        x = keras.layers.Concatenate()([x, skip]) \n",
    "        x = ConvBlock(x, f)\n",
    "\n",
    "        x = ConvBlock(x, 2)\n",
    "        x = keras.layers.Conv2D(filters=1, kernel_size=1, padding='same', activation='linear')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Unet(img_size):\n",
    "    inputs = keras.Input(shape=img_size + (1,))\n",
    "\n",
    "    # 축소 경로\n",
    "    filters = [64, 128, 256, 512, 1024]\n",
    "\n",
    "    x, skips = Encoder(inputs, filters)\n",
    "\n",
    "    # 확장 경로\n",
    "    x = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "\n",
    "    # loss = mse  \n",
    "    model = keras.Model(inputs, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data_generator import DR_Generator\n",
    "\n",
    "masks = ['HardExudate_Masks', 'Hemohedge_Masks', 'Microaneurysms_Masks', 'SoftExudate_Masks']\n",
    "mask_dir = '../data/Seg-set'\n",
    "mask_paths = [os.path.join(mask_dir, mask) for mask in masks]\n",
    "\n",
    "generator_args = {\n",
    "  'dir_path':'../data/Seg-set/Original_Images/',\n",
    "  'mask_path':mask_paths,\n",
    "  'use_mask':True,\n",
    "  'img_size':(512, 512),  \n",
    "  'batch_size':4, # 8로 하면 바로 OOM 뜸\n",
    "  'dataset':'FGADR', # FGADR or EyePacks\n",
    "  'is_train':True\n",
    "}\n",
    "\n",
    "tr_eyepacks_gen = DR_Generator(start_end_index=(0, 500), **generator_args)\n",
    "val_eyepacks_gen = DR_Generator(start_end_index=(500, 600), **generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(img_size=(512, 512))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='mean_squared_error')\n",
    "# model.fit(tr_eyepacks_gen, epochs=1)\n",
    "# unet은 문제없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMD_Unet(img_size, filters):\n",
    "    inputs = keras.Input(shape=img_size + (1,))\n",
    "\n",
    "    # 축소 경로\n",
    "    x, skips = Encoder(inputs, filters)\n",
    "\n",
    "    # 확장 경로\n",
    "    # mask : HardExudate, Hemohedge, Microane, SoftExudates\n",
    "    input_hat = Decoder(x, filters[::-1][1:], skips[::-1]) # 원본 이미지 추정\n",
    "    ex = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "    he = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "    ma = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "    se = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "\n",
    "    model = keras.Model(inputs, outputs=[input_hat, ex, he, ma, se])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72/125 [================>.............] - ETA: 1:04 - loss: 2.0315 - conv2d_25_loss: 0.3040 - conv2d_41_loss: 0.1925 - conv2d_57_loss: 0.0191 - conv2d_73_loss: 0.0141 - conv2d_89_loss: 1.5019"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_141/749820166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMD_Unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_eyepacks_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# trainer class 문제는 아님\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filters = [32, 64, 128, 256, 512]\n",
    "\n",
    "model = SMD_Unet((512, 512), filters)\n",
    "model.compile(loss='mean_squared_error')\n",
    "model.fit(tr_eyepacks_gen, epochs=1)\n",
    "\n",
    "# trainer class 문제는 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
