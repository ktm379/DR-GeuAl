{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "\n",
    "from models import SMD_Unet\n",
    "\n",
    "import numpy as np\n",
    "from data_generator import DR_Generator\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, epochs, optimizer, for_recons, alpha, beta):\n",
    "        '''\n",
    "        for_recons : bool, 학습 단계 구분하기 위함\n",
    "        alpha : recons loss에 곱해줄 가중치\n",
    "        beta : [] , mask loss에 곱해줄 가중치 리스트\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.for_recons = for_recons\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta \n",
    "        if not beta:\n",
    "            self.b1, self.b2, self.b3, self.b4 = beta\n",
    "        \n",
    "        # reconstruction만 학습하는거면 안쓰는 decoder trainable=False로 해주기\n",
    "        if self.for_recons:\n",
    "            self.model.HardExudate.trainable=False\n",
    "            self.model.Hemohedge.trainable=False\n",
    "            self.model.Microane.trainable=False\n",
    "            self.model.SoftExudates.trainable=False\n",
    "        else:\n",
    "            self.model.HardExudate.trainable=True\n",
    "            self.model.Hemohedge.trainable=True\n",
    "            self.model.Microane.trainable=True\n",
    "            self.model.SoftExudates.trainable=True\n",
    "\n",
    "    # loss 함수 계산하는 부분 \n",
    "    # return 값이 텐서여야 하는건가? -> 아마도 그런 것 같다.\n",
    "    def dice_loss(self, inputs, targets, smooth = 1.):\n",
    "        inputs = inputs\n",
    "        targets = targets.numpy()\n",
    "\n",
    "        dice_losses = []\n",
    "        for input, target in zip(inputs, targets): \n",
    "            input_flat = input.flatten()\n",
    "            target_flat = target.flatten()\n",
    "            \n",
    "            intersection = np.sum(input_flat * target_flat)\n",
    "            dice_coef = (2. * intersection + smooth) / (np.sum(input_flat) + np.sum(target_flat) + smooth)\n",
    "\n",
    "            dice_losses.append(1. - dice_coef)\n",
    "            \n",
    "        result = tf.reduce_mean(dice_losses) \n",
    "        return tf.convert_to_tensor(result) # tensor로 바꿔주기\n",
    "    \n",
    "    def mean_square_error(self, input_hats, inputs):\n",
    "        inputs = inputs\n",
    "        input_hats = input_hats.numpy()\n",
    "        \n",
    "        mses = []\n",
    "        for input_hat, input in zip(input_hats, inputs):\n",
    "            mses.append(tf.reduce_mean(tf.square(input_hat - input)).numpy())\n",
    "            \n",
    "        result = np.mean(mses) # 배치 나눠서 계산하고 평균해주기\n",
    "        return tf.convert_to_tensor(result) # tensor로 바꿔주기\n",
    "\n",
    "    @tf.function\n",
    "    def train_on_batch(self, x_batch_train, y_batch_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self.model(x_batch_train, only_recons=self.for_recons)    # 모델이 예측한 결과\n",
    "            input_hat, ex_hat, he_hat, ma_hat, se_hat = preds\n",
    "            \n",
    "            ex, he, ma, se = y_batch_train\n",
    "            \n",
    "            # loss 계산하기\n",
    "            # reconstruction\n",
    "            loss_recons = self.mean_square_error(input_hat, x_batch_train)\n",
    "            \n",
    "            if not self.for_recons:\n",
    "            # ex, he, ma, se\n",
    "                ex_loss = self.dice_loss(ex, ex_hat)\n",
    "                he_loss = self.dice_loss(he, he_hat)\n",
    "                ma_loss = self.dice_loss(ma, ma_hat)\n",
    "                se_loss = self.dice_loss(se, se_hat)            \n",
    "                # loss 가중합 해주기\n",
    "                train_loss = self.b1 * ex_loss + self.b2 * he_loss + self.b3 * ma_loss + self.b4 * se_loss + self.alpha * loss_recons\n",
    "            else:     \n",
    "                train_loss = loss_recons \n",
    "        \n",
    "        grads = tape.gradient(train_loss, self.model.trainable_weights)  # gradient 계산\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))  # Otimizer에게 처리된 그라데이션 적용을 요청\n",
    "\n",
    "        return train_loss, preds\n",
    "\n",
    "    def train(self, train_dataset, val_dataset):\n",
    "        metrics_names = ['train_loss', 'val_loss']\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nEpoch {}/{}\".format(epoch+1, self.epochs))\n",
    "\n",
    "            # train_dataset = train_dataset.take(steps_per_epoch)\n",
    "            # val_dataset = val_dataset.take(val_step)\n",
    "\n",
    "            progBar = Progbar(len(train_dataset), stateful_metrics=metrics_names)\n",
    "\n",
    "            # 데이터 집합의 배치에 대해 반복합니다\n",
    "            for step_train, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                train_loss, logits = self.train_on_batch(x_batch_train, y_batch_train)\n",
    "\n",
    "                # train metric(mean, auc, accuracy 등) 업데이트\n",
    "                # acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "                # train_acc = self.compute_acc(logits, y_batch_train)\n",
    "                values = [('train_loss', train_loss)]\n",
    "                # print('{}'.format((step_train + 1) * self.batch))\n",
    "                progBar.update((step_train + 1) * self.batch, values=values)\n",
    "\n",
    "            for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
    "                preds = self.model(x_batch_val, only_recons=self.for_recons)    # 모델이 예측한 결과\n",
    "                input_hat, ex_hat, he_hat, ma_hat, se_hat = preds\n",
    "                \n",
    "                ex, he, ma, se = y_batch_val\n",
    "                \n",
    "                # loss 계산하기\n",
    "                # reconstruction\n",
    "                loss_recons = self.mean_square_error(input_hat, x_batch_val)\n",
    "                \n",
    "                if not self.for_recons:\n",
    "                # ex, he, ma, se\n",
    "                    ex_loss = self.dice_loss(ex, ex_hat)\n",
    "                    he_loss = self.dice_loss(he, he_hat)\n",
    "                    ma_loss = self.dice_loss(ma, ma_hat)\n",
    "                    se_loss = self.dice_loss(se, se_hat)            \n",
    "                    # loss 가중합 해주기\n",
    "                    val_loss = self.b1 * ex_loss + self.b2 * he_loss + self.b3 * ma_loss + self.b4 * se_loss + self.alpha * loss_recons\n",
    "                else:     \n",
    "                    val_loss = loss_recons \n",
    "                \n",
    "            values = [('train_loss', train_loss), ('val_loss', val_loss)]\n",
    "            progBar.update((step_train + 1) * self.batch, values=values, finalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "masks = ['HardExudate_Masks', 'Hemohedge_Masks', 'Microaneurysms_Masks', 'SoftExudate_Masks']\n",
    "mask_dir = '../data/FGADR-Seg-set_Release/Seg-set'\n",
    "mask_paths = [os.path.join(mask_dir, mask) for mask in masks]\n",
    "\n",
    "generator_args = {\n",
    "  'dir_path':'../data/FGADR-Seg-set_Release/Seg-set/Original_Images/',\n",
    "  'mask_path':mask_paths,\n",
    "  'use_mask':True,\n",
    "  'img_size':(512, 512),  \n",
    "  'batch_size':4, # 8로 하면 바로 OOM 뜸\n",
    "  'dataset':'FGADR', # FGADR or EyePacks\n",
    "  'is_train':True\n",
    "}\n",
    "\n",
    "tr_eyepacks_gen = DR_Generator(start_end_index=(0, 500), **generator_args)\n",
    "val_eyepacks_gen = DR_Generator(start_end_index=(500, 600), **generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"activation_894\" \"                 f\"(type Activation).\n\n{{function_node __wrapped__Relu_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[4,256,256,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Relu]\n\nCall arguments received by layer \"activation_894\" \"                 f\"(type Activation):\n  • inputs=tf.Tensor(shape=(4, 256, 256, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m trainer_args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:model,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[0;32m     14\u001b[0m }\n\u001b[0;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrainer_args)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtr_eyepacks_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m              \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_eyepacks_gen\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[54], line 110\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# 데이터 집합의 배치에 대해 반복합니다\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_train, (x_batch_train, y_batch_train) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[1;32m--> 110\u001b[0m     train_loss, logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# train metric(mean, auc, accuracy 등) 업데이트\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# acc_metric.update_state(y_batch_train, logits)\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# train_acc = self.compute_acc(logits, y_batch_train)\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     values \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, train_loss)]\n",
      "File \u001b[1;32mc:\\Users\\Hi\\miniconda3\\envs\\genAI_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[54], line 72\u001b[0m, in \u001b[0;36mTrainer.train_on_batch\u001b[1;34m(self, x_batch_train, y_batch_train)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_on_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_batch_train, y_batch_train):\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 72\u001b[0m         preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_recons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_recons\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# 모델이 예측한 결과\u001b[39;00m\n\u001b[0;32m     73\u001b[0m         input_hat, ex_hat, he_hat, ma_hat, se_hat \u001b[38;5;241m=\u001b[39m preds\n\u001b[0;32m     75\u001b[0m         ex, he, ma, se \u001b[38;5;241m=\u001b[39m y_batch_train\n",
      "File \u001b[1;32mc:\\Users\\Hi\\miniconda3\\envs\\genAI_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Hi\\Desktop\\VISUWORKS\\code\\models.py:161\u001b[0m, in \u001b[0;36mSMD_Unet.call\u001b[1;34m(self, inputs, only_recons)\u001b[0m\n\u001b[0;32m    159\u001b[0m x, skips \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(inputs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Decoder\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m input_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskips\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# reconstruction만 학습할 때 구분\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m only_recons:     \n",
      "File \u001b[1;32mc:\\Users\\Hi\\Desktop\\VISUWORKS\\code\\models.py:131\u001b[0m, in \u001b[0;36mDecoderBlock.call\u001b[1;34m(self, x, skips)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, skips):\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m skip, upsample_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(skips, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample_blocks):\n\u001b[1;32m--> 131\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mupsample_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_block(x)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Hi\\Desktop\\VISUWORKS\\code\\models.py:94\u001b[0m, in \u001b[0;36mUpsampleBlock.call\u001b[1;34m(self, x, skip)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, skip):\n\u001b[0;32m     93\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_T(x)\n\u001b[1;32m---> 94\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat([x, skip])\n\u001b[0;32m     96\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_block_2(x)\n",
      "File \u001b[1;32mc:\\Users\\Hi\\Desktop\\VISUWORKS\\code\\models.py:79\u001b[0m, in \u001b[0;36mConvBlock.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m     78\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[1;32m---> 79\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"activation_894\" \"                 f\"(type Activation).\n\n{{function_node __wrapped__Relu_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[4,256,256,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Relu]\n\nCall arguments received by layer \"activation_894\" \"                 f\"(type Activation):\n  • inputs=tf.Tensor(shape=(4, 256, 256, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
    "\n",
    "model = SMD_Unet()\n",
    "\n",
    "trainer_args = {\n",
    "    'model':model,\n",
    "    'epochs':1,\n",
    "    'optimizer':optimizer,\n",
    "    'for_recons':False,\n",
    "    'alpha':1.0,\n",
    "    'beta':[1.0, 1.0, 1.0, 1.0]\n",
    "}\n",
    "trainer = Trainer(**trainer_args)\n",
    "\n",
    "trainer.train(train_dataset=tr_eyepacks_gen,\n",
    "              val_dataset=val_eyepacks_gen\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고 코드\n",
    "# https://pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/\n",
    "\n",
    "# initialize our FashionNet multi-output network\n",
    "model = FashionNet.build(96, 96,\n",
    "\tnumCategories=len(categoryLB.classes_),\n",
    "\tnumColors=len(colorLB.classes_),\n",
    "\tfinalAct=\"softmax\")\n",
    "# define two dictionaries: one that specifies the loss method for\n",
    "# each output of the network along with a second dictionary that\n",
    "# specifies the weight per loss\n",
    "losses = {\n",
    "\t\"category_output\": \"categorical_crossentropy\",\n",
    "\t\"color_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"category_output\": 1.0, \"color_output\": 1.0}\n",
    "# initialize the optimizer and compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "H = model.fit(x=trainX,\n",
    "\ty={\"category_output\": trainCategoryY, \"color_output\": trainColorY},\n",
    "\tvalidation_data=(testX,\n",
    "\t\t{\"category_output\": testCategoryY, \"color_output\": testColorY}),\n",
    "\tepochs=EPOCHS,\n",
    "\tverbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
