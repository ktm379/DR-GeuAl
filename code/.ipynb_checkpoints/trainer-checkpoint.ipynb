{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "\n",
    "from models import SMD_Unet\n",
    "\n",
    "import numpy as np\n",
    "from data_generator import DR_Generator\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, epochs, optimizer, for_recons, alpha, beta=None):\n",
    "        '''\n",
    "        for_recons : bool, 학습 단계 구분하기 위함\n",
    "        alpha : recons loss에 곱해줄 가중치\n",
    "        beta : [] , mask loss에 곱해줄 가중치 리스트\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.for_recons = for_recons\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta \n",
    "        if beta!=None:\n",
    "            self.b1, self.b2, self.b3, self.b4 = beta\n",
    "        \n",
    "        # reconstruction만 학습하는거면 안쓰는 decoder trainable=False로 해주기\n",
    "        if self.for_recons:\n",
    "            self.model.HardExudate.trainable=False\n",
    "            self.model.Hemohedge.trainable=False\n",
    "            self.model.Microane.trainable=False\n",
    "            self.model.SoftExudates.trainable=False\n",
    "        else:\n",
    "            self.model.HardExudate.trainable=True\n",
    "            self.model.Hemohedge.trainable=True\n",
    "            self.model.Microane.trainable=True\n",
    "            self.model.SoftExudates.trainable=True\n",
    "\n",
    "    # loss 함수 계산하는 부분 \n",
    "    # return 값이 텐서여야 하는건가? -> 아마도 그런 것 같다.\n",
    "    def dice_loss(self, inputs, targets, smooth = 1.):\n",
    "        inputs = inputs\n",
    "        targets = targets.numpy()\n",
    "\n",
    "        dice_losses = []\n",
    "        for input, target in zip(inputs, targets): \n",
    "            input_flat = input.flatten()\n",
    "            target_flat = target.flatten()\n",
    "            \n",
    "            intersection = np.sum(input_flat * target_flat)\n",
    "            dice_coef = (2. * intersection + smooth) / (np.sum(input_flat) + np.sum(target_flat) + smooth)\n",
    "\n",
    "            dice_losses.append(1. - dice_coef)\n",
    "            \n",
    "        result = tf.reduce_mean(dice_losses) \n",
    "        return tf.convert_to_tensor(result) # tensor로 바꿔주기\n",
    "    \n",
    "    def mean_square_error(self, input_hats, inputs):\n",
    "        inputs = inputs\n",
    "        input_hats = input_hats.numpy()\n",
    "        \n",
    "        mses = []\n",
    "        for input_hat, input in zip(input_hats, inputs):\n",
    "            mses.append(tf.reduce_mean(tf.square(input_hat - input)).numpy())\n",
    "            \n",
    "        result = np.mean(mses) # 배치 나눠서 계산하고 평균해주기\n",
    "        return tf.convert_to_tensor(result) # tensor로 바꿔주기\n",
    "\n",
    "    @tf.function\n",
    "    def train_on_batch(self, x_batch_train, y_batch_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self.model(x_batch_train, only_recons=self.for_recons)    # 모델이 예측한 결과\n",
    "#             input_hat, ex_hat, he_hat, ma_hat, se_hat = preds\n",
    "            \n",
    "#             ex, he, ma, se = y_batch_train\n",
    "            \n",
    "            # loss 계산하기\n",
    "            # reconstruction\n",
    "            loss_recons = self.mean_square_error(preds[0], x_batch_train)\n",
    "            \n",
    "            if not self.for_recons:\n",
    "            # ex, he, ma, se\n",
    "                ex_loss = self.dice_loss(y_batch_train[0], preds[1])\n",
    "                he_loss = self.dice_loss(y_batch_train[1], preds[2])\n",
    "                ma_loss = self.dice_loss(y_batch_train[2], preds[3])\n",
    "                se_loss = self.dice_loss(y_batch_train[3], preds[4])            \n",
    "                # loss 가중합 해주기\n",
    "                train_loss = self.b1 * ex_loss + self.b2 * he_loss + self.b3 * ma_loss + self.b4 * se_loss + self.alpha * loss_recons\n",
    "            else:     \n",
    "                train_loss = loss_recons \n",
    "            \n",
    "        grads = tape.gradient(train_loss, self.model.trainable_weights)  # gradient 계산\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))  # Otimizer에게 처리된 그라데이션 적용을 요청\n",
    "        \n",
    "        del preds\n",
    "        \n",
    "        return train_loss\n",
    "\n",
    "    def train(self, train_dataset, val_dataset):\n",
    "        metrics_names = ['train_loss', 'val_loss']\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nEpoch {}/{}\".format(epoch+1, self.epochs))\n",
    "\n",
    "            # train_dataset = train_dataset.take(steps_per_epoch)\n",
    "            # val_dataset = val_dataset.take(val_step)\n",
    "\n",
    "            progBar = Progbar(len(train_dataset), stateful_metrics=metrics_names)\n",
    "\n",
    "            # 데이터 집합의 배치에 대해 반복합니다\n",
    "            for step_train, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                train_loss = self.train_on_batch(x_batch_train, y_batch_train)\n",
    "\n",
    "                # train metric(mean, auc, accuracy 등) 업데이트\n",
    "                # acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "                # train_acc = self.compute_acc(logits, y_batch_train)\n",
    "                values = [('train_loss', train_loss)]\n",
    "                # print('{}'.format((step_train + 1) * self.batch))\n",
    "                progBar.update((step_train + 1) * self.batch, values=values)\n",
    "                \n",
    "                del train_loss\n",
    "                del x_batch_train\n",
    "                del y_batch_train\n",
    "\n",
    "            for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
    "                preds = self.model(x_batch_val, only_recons=self.for_recons)    # 모델이 예측한 결과\n",
    "#                 input_hat, ex_hat, he_hat, ma_hat, se_hat = preds\n",
    "                \n",
    "#                 ex, he, ma, se = y_batch_val\n",
    "                \n",
    "                # loss 계산하기\n",
    "                # reconstruction\n",
    "                loss_recons = self.mean_square_error(preds[0], x_batch_val)\n",
    "                \n",
    "                if not self.for_recons:\n",
    "                # ex, he, ma, se\n",
    "                    ex_loss = self.dice_loss(y_batch_val[0], preds[1])\n",
    "                    he_loss = self.dice_loss(y_batch_val[1], preds[2])\n",
    "                    ma_loss = self.dice_loss(y_batch_val[2], preds[3])\n",
    "                    se_loss = self.dice_loss(y_batch_val[3], preds[4])            \n",
    "                    # loss 가중합 해주기\n",
    "                    val_loss = self.b1 * ex_loss + self.b2 * he_loss + self.b3 * ma_loss + self.b4 * se_loss + self.alpha * loss_recons\n",
    "                else:     \n",
    "                    val_loss = loss_recons\n",
    "                    \n",
    "                del val_loss\n",
    "                del x_batch_val\n",
    "                del y_batch_val\n",
    "                del preds\n",
    "                \n",
    "            values = [('train_loss', train_loss), ('val_loss', val_loss)]\n",
    "            progBar.update((step_train + 1) * self.batch, values=values, finalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"smd__unet_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_block_7 (EncoderBloc multiple                  18857920  \n",
      "_________________________________________________________________\n",
      "decoder_block_35 (DecoderBlo multiple                  12197325  \n",
      "_________________________________________________________________\n",
      "decoder_block_36 (DecoderBlo multiple                  12197325  \n",
      "_________________________________________________________________\n",
      "decoder_block_37 (DecoderBlo multiple                  12197325  \n",
      "_________________________________________________________________\n",
      "decoder_block_38 (DecoderBlo multiple                  12197325  \n",
      "_________________________________________________________________\n",
      "decoder_block_39 (DecoderBlo multiple                  12197325  \n",
      "=================================================================\n",
      "Total params: 79,844,545\n",
      "Trainable params: 79,817,389\n",
      "Non-trainable params: 27,156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SMD_Unet()\n",
    "model.build(input_shape=(None, 512, 512, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "masks = ['HardExudate_Masks', 'Hemohedge_Masks', 'Microaneurysms_Masks', 'SoftExudate_Masks']\n",
    "mask_dir = '../data/Seg-set'\n",
    "mask_paths = [os.path.join(mask_dir, mask) for mask in masks]\n",
    "\n",
    "generator_args = {\n",
    "  'dir_path':'../data/Seg-set/Original_Images/',\n",
    "  'mask_path':mask_paths,\n",
    "  'use_mask':True,\n",
    "  'img_size':(256, 256),  \n",
    "  'batch_size':2, # 8로 하면 바로 OOM 뜸\n",
    "  'dataset':'FGADR', # FGADR or EyePacks\n",
    "  'is_train':True\n",
    "}\n",
    "\n",
    "tr_eyepacks_gen = DR_Generator(start_end_index=(0, 500), **generator_args)\n",
    "val_eyepacks_gen = DR_Generator(start_end_index=(500, 600), **generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Unet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_110/4178707191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = SMD_Unet()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m trainer_args = {\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Unet' is not defined"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
    "\n",
    "model = SMD_Unet()\n",
    "\n",
    "trainer_args = {\n",
    "    'model':model,\n",
    "    'epochs':1,\n",
    "    'optimizer':optimizer,\n",
    "    'for_recons':True,\n",
    "    'alpha':1.0,\n",
    "    'beta':[1.0, 1.0, 1.0, 1.0]\n",
    "}\n",
    "trainer = Trainer(**trainer_args)\n",
    "\n",
    "trainer.train(train_dataset=tr_eyepacks_gen,\n",
    "              val_dataset=val_eyepacks_gen\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def ConvBlock(x, n_filters):\n",
    "    x = keras.layers.Conv2D(n_filters, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def UpsampleBlock(x, skip, n_filters):\n",
    "    x = keras.layers.Conv2DTranspose(n_filters, (2, 2), strides=2, padding='same')(x)\n",
    "    x = keras.layers.Concatenate()([x, skip]) \n",
    "    x = ConvBlock(x, n_filters)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Encoder(x, filters):\n",
    "    skips = []\n",
    "\n",
    "    for f in filters:\n",
    "        x = ConvBlock(x, f)\n",
    "        x = ConvBlock(x, f)\n",
    "        # 맨 마지막 층을 제외하고는 skip connection, downsampling을 진행\n",
    "        if f != 1024:\n",
    "            skips.append(x)\n",
    "            x = keras.layers.MaxPooling2D(2)(x)\n",
    "      \n",
    "    return x, skips\n",
    "\n",
    "def Decoder(x, filters, skips):\n",
    "    for f, skip in zip(filters, skips):\n",
    "        x = keras.layers.Conv2DTranspose(f, (2, 2), strides=2, padding='same')(x)\n",
    "        x = ConvBlock(x, f)\n",
    "        x = keras.layers.Concatenate()([x, skip]) \n",
    "        x = ConvBlock(x, f)\n",
    "\n",
    "        x = ConvBlock(x, 2)\n",
    "        x = keras.layers.Conv2D(filters=1, kernel_size=1, padding='same', activation='linear')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Unet(img_size):\n",
    "    inputs = keras.Input(shape=img_size + (1,))\n",
    "\n",
    "    # 축소 경로\n",
    "    filters = [64, 128, 256, 512, 1024]\n",
    "\n",
    "    x, skips = Encoder(inputs, filters)\n",
    "\n",
    "    # 확장 경로\n",
    "    x = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "\n",
    "    # loss = mse  \n",
    "    model = keras.Model(inputs, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "masks = ['HardExudate_Masks', 'Hemohedge_Masks', 'Microaneurysms_Masks', 'SoftExudate_Masks']\n",
    "mask_dir = '../data/Seg-set'\n",
    "mask_paths = [os.path.join(mask_dir, mask) for mask in masks]\n",
    "\n",
    "generator_args = {\n",
    "  'dir_path':'../data/Seg-set/Original_Images/',\n",
    "  'mask_path':mask_paths,\n",
    "  'use_mask':True,\n",
    "  'img_size':(512, 512),  \n",
    "  'batch_size':4, # 8로 하면 바로 OOM 뜸\n",
    "  'dataset':'FGADR', # FGADR or EyePacks\n",
    "  'is_train':True\n",
    "}\n",
    "\n",
    "tr_eyepacks_gen = DR_Generator(start_end_index=(0, 500), **generator_args)\n",
    "val_eyepacks_gen = DR_Generator(start_end_index=(500, 600), **generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(img_size=(512, 512))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='mean_squared_error')\n",
    "# model.fit(tr_eyepacks_gen, epochs=1)\n",
    "# unet은 문제없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMD_Unet(img_size):\n",
    "    inputs = keras.Input(shape=img_size + (1,))\n",
    "\n",
    "    # 축소 경로\n",
    "    filters = [64, 128, 256, 512, 1024]\n",
    "\n",
    "    x, skips = Encoder(inputs, filters)\n",
    "\n",
    "    # 확장 경로\n",
    "    # mask : HardExudate, Hemohedge, Microane, SoftExudates\n",
    "    input_hat = Decoder(x, filters[::-1][1:], skips[::-1]) # 원본 이미지 추정\n",
    "    ex = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "    he = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "    ma = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "    se = Decoder(x, filters[::-1][1:], skips[::-1])\n",
    "\n",
    "    model = keras.Model(inputs, outputs=[input_hat, ex, he, ma, se])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SMD_Unet((512, 512))\n",
    "# model.compile(loss='mean_squared_error')\n",
    "# model.fit(tr_eyepacks_gen, epochs=1)\n",
    "\n",
    "# trainer class 문제는 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
