{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.data_generator import DR_Generator\n",
    "import os\n",
    "from assets.models import SMD_Unet\n",
    "from assets.trainer import Trainer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = ['HardExudate_Masks', 'Hemohedge_Masks', 'Microaneurysms_Masks', 'SoftExudate_Masks']\n",
    "mask_dir = '../data/FGADR/Seg-set'\n",
    "mask_paths = [os.path.join(mask_dir, mask) for mask in masks]\n",
    "\n",
    "generator_args = {\n",
    "    'dir_path':'../data/FGADR/Seg-set/Original_Images/',\n",
    "    'mask_path':mask_paths,\n",
    "    'use_mask':True,\n",
    "    'img_size':(512, 512),  \n",
    "    'batch_size':4, # 8로 하면 바로 OOM 뜸\n",
    "    'dataset':'FGADR', # FGADR or EyePacks\n",
    "    'use_3channel':False,\n",
    "    'CLAHE_args':None,\n",
    "    'add_noise_std':0.2\n",
    "}\n",
    "\n",
    "tr_fgadr_gen = DR_Generator(start_end_index=(0, 1292), is_train=True, **generator_args)\n",
    "val_fgadr_gen = DR_Generator(start_end_index=(1292, 1476), is_train=False, **generator_args)\n",
    "ts_fgadr_gen = DR_Generator(start_end_index=(1476, 1842), is_train=False, **generator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SMD_Unet(enc_filters=[64, 128, 256, 512, 1024], dec_filters=[512, 256, 64, 32], input_channel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc7b0ada640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_weights('../models/with_recons_1channel_CLAHE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/130\n",
      "1292/1292 [==============================] - 467s 362ms/step - train_loss: 0.7077 - mask_loss: 0.7863 - loss_recons: 4.9851e-05\n",
      "184/184 [==============================] - 42s 231ms/step - val_loss: 0.7994 - mask_loss: 0.8882 - loss_recons: 5.8836e-05\n",
      "\n",
      "Epoch 2/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.7051 - mask_loss: 0.7834 - loss_recons: 5.0328e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.8074 - mask_loss: 0.8971 - loss_recons: 5.5365e-05\n",
      "\n",
      "Epoch 3/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.7022 - mask_loss: 0.7802 - loss_recons: 4.8523e-05\n",
      "184/184 [==============================] - 42s 228ms/step - val_loss: 0.8016 - mask_loss: 0.8906 - loss_recons: 4.5845e-05\n",
      "\n",
      "Epoch 4/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6987 - mask_loss: 0.7763 - loss_recons: 5.0509e-05\n",
      "184/184 [==============================] - 42s 228ms/step - val_loss: 0.7957 - mask_loss: 0.8842 - loss_recons: 5.2639e-05\n",
      "\n",
      "Epoch 5/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6951 - mask_loss: 0.7723 - loss_recons: 4.9820e-05\n",
      "184/184 [==============================] - 42s 229ms/step - val_loss: 0.7959 - mask_loss: 0.8843 - loss_recons: 5.4873e-05\n",
      "\n",
      "Epoch 6/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6915 - mask_loss: 0.7683 - loss_recons: 4.9214e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7912 - mask_loss: 0.8791 - loss_recons: 5.2460e-05\n",
      "\n",
      "Epoch 7/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6879 - mask_loss: 0.7643 - loss_recons: 4.7699e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7930 - mask_loss: 0.8812 - loss_recons: 4.8708e-05\n",
      "\n",
      "Epoch 8/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6844 - mask_loss: 0.7604 - loss_recons: 4.6608e-05\n",
      "184/184 [==============================] - 42s 228ms/step - val_loss: 0.7929 - mask_loss: 0.8810 - loss_recons: 4.4615e-05\n",
      "\n",
      "Epoch 9/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6805 - mask_loss: 0.7561 - loss_recons: 4.4379e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7985 - mask_loss: 0.8872 - loss_recons: 4.2460e-05\n",
      "\n",
      "Epoch 10/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6764 - mask_loss: 0.7516 - loss_recons: 4.7480e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7936 - mask_loss: 0.8818 - loss_recons: 4.7423e-05\n",
      "\n",
      "Epoch 11/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6731 - mask_loss: 0.7479 - loss_recons: 4.9267e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7939 - mask_loss: 0.8821 - loss_recons: 4.3167e-05\n",
      "\n",
      "Epoch 12/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6694 - mask_loss: 0.7438 - loss_recons: 4.5570e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7872 - mask_loss: 0.8746 - loss_recons: 4.1139e-05\n",
      "\n",
      "Epoch 13/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6653 - mask_loss: 0.7393 - loss_recons: 4.4777e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7877 - mask_loss: 0.8752 - loss_recons: 4.1459e-05\n",
      "\n",
      "Epoch 14/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6618 - mask_loss: 0.7354 - loss_recons: 4.4574e-05\n",
      "184/184 [==============================] - 42s 228ms/step - val_loss: 0.7869 - mask_loss: 0.8743 - loss_recons: 3.9969e-05\n",
      "\n",
      "Epoch 15/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6585 - mask_loss: 0.7316 - loss_recons: 4.7386e-05\n",
      "184/184 [==============================] - 42s 228ms/step - val_loss: 0.7899 - mask_loss: 0.8776 - loss_recons: 3.7594e-05\n",
      "\n",
      "Epoch 16/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6550 - mask_loss: 0.7278 - loss_recons: 4.7747e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7815 - mask_loss: 0.8684 - loss_recons: 3.9318e-05\n",
      "\n",
      "Epoch 17/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6508 - mask_loss: 0.7231 - loss_recons: 4.5762e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7816 - mask_loss: 0.8684 - loss_recons: 4.0301e-05\n",
      "\n",
      "Epoch 18/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6468 - mask_loss: 0.7187 - loss_recons: 4.4032e-05\n",
      "184/184 [==============================] - 42s 228ms/step - val_loss: 0.7765 - mask_loss: 0.8627 - loss_recons: 4.1722e-05\n",
      "\n",
      "Epoch 19/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6428 - mask_loss: 0.7142 - loss_recons: 4.4602e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7759 - mask_loss: 0.8621 - loss_recons: 4.2593e-05\n",
      "\n",
      "Epoch 20/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.6389 - mask_loss: 0.7099 - loss_recons: 4.7672e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7745 - mask_loss: 0.8605 - loss_recons: 5.0916e-05\n",
      "\n",
      "Epoch 21/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6350 - mask_loss: 0.7055 - loss_recons: 4.7243e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7766 - mask_loss: 0.8629 - loss_recons: 4.4170e-05\n",
      "\n",
      "Epoch 22/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.6311 - mask_loss: 0.7012 - loss_recons: 4.5400e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7739 - mask_loss: 0.8598 - loss_recons: 4.3910e-05\n",
      "\n",
      "Epoch 23/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6271 - mask_loss: 0.6968 - loss_recons: 4.7824e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7714 - mask_loss: 0.8571 - loss_recons: 4.5882e-05\n",
      "\n",
      "Epoch 24/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6232 - mask_loss: 0.6925 - loss_recons: 4.8013e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7709 - mask_loss: 0.8565 - loss_recons: 5.4370e-05\n",
      "\n",
      "Epoch 25/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.6198 - mask_loss: 0.6886 - loss_recons: 4.9599e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7726 - mask_loss: 0.8584 - loss_recons: 4.4500e-05\n",
      "\n",
      "Epoch 26/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.6158 - mask_loss: 0.6842 - loss_recons: 4.9930e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7686 - mask_loss: 0.8540 - loss_recons: 5.3962e-05\n",
      "\n",
      "Epoch 27/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.6124 - mask_loss: 0.6804 - loss_recons: 5.0618e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7702 - mask_loss: 0.8558 - loss_recons: 5.6016e-05\n",
      "\n",
      "Epoch 28/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.6080 - mask_loss: 0.6756 - loss_recons: 5.0601e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7716 - mask_loss: 0.8573 - loss_recons: 5.1144e-05\n",
      "\n",
      "Epoch 29/130\n",
      "1292/1292 [==============================] - 449s 347ms/step - train_loss: 0.6040 - mask_loss: 0.6712 - loss_recons: 4.9701e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7686 - mask_loss: 0.8540 - loss_recons: 4.8501e-05\n",
      "\n",
      "Epoch 30/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.5998 - mask_loss: 0.6665 - loss_recons: 4.5364e-05\n",
      "184/184 [==============================] - 41s 225ms/step - val_loss: 0.7593 - mask_loss: 0.8437 - loss_recons: 4.3379e-05\n",
      "\n",
      "Epoch 31/130\n",
      "1292/1292 [==============================] - 450s 349ms/step - train_loss: 0.5955 - mask_loss: 0.6617 - loss_recons: 4.7759e-05\n",
      "184/184 [==============================] - 45s 243ms/step - val_loss: 0.7585 - mask_loss: 0.8428 - loss_recons: 4.6136e-05\n",
      "\n",
      "Epoch 32/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.5915 - mask_loss: 0.6572 - loss_recons: 4.7525e-05\n",
      "184/184 [==============================] - 43s 236ms/step - val_loss: 0.7553 - mask_loss: 0.8392 - loss_recons: 5.6625e-05\n",
      "\n",
      "Epoch 33/130\n",
      "1292/1292 [==============================] - 450s 348ms/step - train_loss: 0.5871 - mask_loss: 0.6523 - loss_recons: 4.7196e-05\n",
      "184/184 [==============================] - 43s 235ms/step - val_loss: 0.7538 - mask_loss: 0.8375 - loss_recons: 4.8985e-05\n",
      "\n",
      "Epoch 34/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.5829 - mask_loss: 0.6477 - loss_recons: 4.5874e-05\n",
      "184/184 [==============================] - 43s 231ms/step - val_loss: 0.7537 - mask_loss: 0.8374 - loss_recons: 4.3862e-05\n",
      "\n",
      "Epoch 35/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.5789 - mask_loss: 0.6432 - loss_recons: 4.4060e-05\n",
      "184/184 [==============================] - 42s 227ms/step - val_loss: 0.7596 - mask_loss: 0.8440 - loss_recons: 4.6090e-05\n",
      "\n",
      "Epoch 36/130\n",
      "1292/1292 [==============================] - 449s 347ms/step - train_loss: 0.5749 - mask_loss: 0.6388 - loss_recons: 4.6848e-05\n",
      "184/184 [==============================] - 41s 225ms/step - val_loss: 0.7563 - mask_loss: 0.8403 - loss_recons: 4.7560e-05\n",
      "\n",
      "Epoch 37/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.5708 - mask_loss: 0.6342 - loss_recons: 4.6917e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7624 - mask_loss: 0.8471 - loss_recons: 5.1029e-05\n",
      "\n",
      "Epoch 38/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.5665 - mask_loss: 0.6295 - loss_recons: 4.4544e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7640 - mask_loss: 0.8489 - loss_recons: 3.8429e-05\n",
      "\n",
      "Epoch 39/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.5628 - mask_loss: 0.6254 - loss_recons: 4.7724e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7601 - mask_loss: 0.8446 - loss_recons: 4.4384e-05\n",
      "\n",
      "Epoch 40/130\n",
      "1292/1292 [==============================] - 449s 348ms/step - train_loss: 0.5604 - mask_loss: 0.6227 - loss_recons: 4.9039e-05\n",
      "184/184 [==============================] - 42s 226ms/step - val_loss: 0.7618 - mask_loss: 0.8464 - loss_recons: 5.2006e-05\n",
      "\n",
      "Epoch 41/130\n",
      "1136/1292 [=========================>....] - ETA: 54s - train_loss: 0.6040 - mask_loss: 0.6711 - loss_recons: 4.4725e-05"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
    "\n",
    "trainer_args = {\n",
    "    'model':model,\n",
    "    'epochs':100,\n",
    "    'optimizer':optimizer,\n",
    "    'for_recons':False,\n",
    "    'alpha':0.1,\n",
    "    'beta':None,\n",
    "    'first_epoch':1,\n",
    "    'file_name':'history/with_recons_3channel_CLAHE_74.txt',\n",
    "    'save_model_path':'../models/with_recons_1channel_CLAHE',\n",
    "    'add_noise':True\n",
    "}\n",
    "trainer = Trainer(**trainer_args)\n",
    "\n",
    "history = trainer.train(train_dataset=tr_fgadr_gen,\n",
    "                        val_dataset=val_fgadr_gen,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
